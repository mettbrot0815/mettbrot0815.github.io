<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>llm-auto-setup ‚Äî Local LLM Stack in One Command</title>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Syne:wght@400;600;700;800&family=JetBrains+Mono:wght@300;400;500;700&display=swap" rel="stylesheet">
<style>
*,*::before,*::after{box-sizing:border-box;margin:0;padding:0}
:root{
  --bg:#0b0d0f;--bg2:#111418;--bg3:#181c22;
  --border:#252c35;--border2:#2e3840;
  --amber:#f5a623;--amber-dim:#c4861c;--amber-glow:rgba(245,166,35,.14);
  --green:#52d98a;--cyan:#5bc8d0;--red:#e05c5c;
  --text:#d4d8df;--text-dim:#7a8494;--text-faint:#3e4852;
  --mono:'JetBrains Mono',monospace;--sans:'Syne',sans-serif;
}
html{scroll-behavior:smooth}
body{background:var(--bg);color:var(--text);font-family:var(--sans);font-size:16px;line-height:1.6;overflow-x:hidden}
body::before{content:'';position:fixed;inset:0;background-image:url("data:image/svg+xml,%3Csvg viewBox='0 0 200 200' xmlns='http://www.w3.org/2000/svg'%3E%3Cfilter id='n'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='0.85' numOctaves='4' stitchTiles='stitch'/%3E%3C/filter%3E%3Crect width='100%25' height='100%25' filter='url(%23n)' opacity='0.04'/%3E%3C/svg%3E");pointer-events:none;z-index:9999;opacity:.45}
.container{max-width:1100px;margin:0 auto;padding:0 2rem}
a{color:var(--amber);text-decoration:none}
a:hover{text-decoration:underline}

/* Nav */
nav{position:sticky;top:0;z-index:100;border-bottom:1px solid var(--border);background:rgba(11,13,15,.88);backdrop-filter:blur(14px)}
.nav-inner{display:flex;align-items:center;justify-content:space-between;padding:.85rem 2rem;max-width:1100px;margin:0 auto}
.nav-logo{font-family:var(--mono);font-weight:700;font-size:.98rem;color:var(--amber);letter-spacing:-.02em}
.nav-logo span{color:var(--text-faint);font-weight:300}
.nav-links{display:flex;gap:2rem}
.nav-links a{font-family:var(--mono);font-size:.75rem;color:var(--text-dim);letter-spacing:.06em;text-transform:uppercase;transition:color .15s}
.nav-links a:hover{color:var(--amber);text-decoration:none}
.nav-gh{display:flex;align-items:center;gap:.45rem;font-family:var(--mono);font-size:.78rem;font-weight:700;color:var(--bg);background:var(--amber);padding:.38rem .85rem;border-radius:3px;transition:background .15s}
.nav-gh:hover{background:var(--amber-dim);text-decoration:none;color:var(--bg)}
.nav-gh svg{width:15px;height:15px}

/* Hero */
#hero{padding:7rem 2rem 5rem;position:relative;overflow:hidden}
#hero::before{content:'';position:absolute;top:-8%;left:50%;transform:translateX(-50%);width:860px;height:480px;background:radial-gradient(ellipse,rgba(245,166,35,.065) 0%,transparent 68%);pointer-events:none}
.hero-eyebrow{font-family:var(--mono);font-size:.76rem;font-weight:500;color:var(--amber);letter-spacing:.18em;text-transform:uppercase;margin-bottom:1.3rem;opacity:0;animation:fadeUp .5s .1s forwards}
.hero-title{font-size:clamp(2.5rem,5.8vw,4.5rem);font-weight:800;line-height:1.06;letter-spacing:-.03em;color:#edf0f4;max-width:800px;opacity:0;animation:fadeUp .5s .2s forwards}
.hero-title .hl{color:var(--amber)}
.hero-sub{margin-top:1.3rem;font-size:1.1rem;color:var(--text-dim);max-width:560px;line-height:1.72;opacity:0;animation:fadeUp .5s .3s forwards}
.badges{display:flex;flex-wrap:wrap;gap:.55rem;margin-top:2rem;opacity:0;animation:fadeUp .5s .38s forwards}
.badge{font-family:var(--mono);font-size:.7rem;font-weight:500;padding:.28rem .7rem;border-radius:2px;border:1px solid var(--border2);background:var(--bg2);color:var(--text-dim);display:flex;align-items:center;gap:.38rem}
.badge .dot{width:5px;height:5px;border-radius:50%}
.badge.nv .dot{background:#76b900}.badge.amd .dot{background:#ed1c24}.badge.cpu .dot{background:var(--cyan)}.badge.ub .dot{background:#e95420}
.install-strip{display:flex;align-items:stretch;margin-top:2.4rem;max-width:620px;border:1px solid var(--border2);border-radius:4px;overflow:hidden;background:var(--bg2);opacity:0;animation:fadeUp .5s .46s forwards;box-shadow:0 0 36px rgba(245,166,35,.055)}
.install-cmd{flex:1;padding:.85rem 1.15rem;font-family:var(--mono);font-size:.83rem;color:var(--green);background:var(--bg2);white-space:nowrap;overflow-x:auto;border:none;outline:none;cursor:text;user-select:all}
.install-cmd .ps{color:var(--text-faint)}
.copy-btn{padding:.85rem 1.1rem;font-family:var(--mono);font-size:.72rem;font-weight:700;color:var(--amber);background:var(--bg3);border:none;border-left:1px solid var(--border2);cursor:pointer;transition:background .15s,color .15s;white-space:nowrap}
.copy-btn:hover{background:var(--amber-glow);color:#fff}
.copy-btn.ok{color:var(--green)}

/* Hero split */
.hero-split{display:grid;grid-template-columns:1fr 1fr;gap:3.5rem;align-items:start;margin-top:4.5rem}
@media(max-width:800px){.hero-split{grid-template-columns:1fr}.term-win{display:none}}
.hero-bullets{display:flex;flex-direction:column;gap:1.15rem;padding-top:.4rem;opacity:0;animation:fadeUp .55s .55s forwards}
.bullet{display:flex;gap:.9rem;align-items:flex-start}
.bullet-arrow{color:var(--amber);font-size:1rem;margin-top:.1rem;flex-shrink:0}
.bullet-title{font-weight:700;color:#edf0f4;margin-bottom:.22rem;font-size:.97rem}
.bullet-body{font-size:.87rem;color:var(--text-dim);line-height:1.62}

/* Terminal */
.term-win{border:1px solid var(--border2);border-radius:6px;overflow:hidden;background:var(--bg2);box-shadow:0 22px 72px rgba(0,0,0,.55),0 0 0 1px rgba(255,255,255,.025);opacity:0;animation:fadeUp .6s .52s forwards}
.term-bar{display:flex;align-items:center;gap:.45rem;padding:.65rem .95rem;background:var(--bg3);border-bottom:1px solid var(--border)}
.td{width:9px;height:9px;border-radius:50%}.td.r{background:#ff5f57}.td.y{background:#febc2e}.td.g{background:#28c840}
.term-bar .ttl{font-family:var(--mono);font-size:.68rem;color:var(--text-faint);margin:0 auto}
.term-body{padding:1.1rem 1.3rem;min-height:350px;font-family:var(--mono);font-size:.76rem;line-height:1.82}
.tl{display:block}.tc{color:var(--cyan)}.tg{color:var(--green)}.ta{color:var(--amber)}.tw{color:#edf0f4}.td2{color:var(--text-faint)}
.tcur{display:inline-block;width:7px;height:.92em;background:var(--amber);vertical-align:text-bottom;animation:blink 1s step-end infinite}

/* Shared section */
.section{padding:5.5rem 2rem}.section-alt{background:var(--bg2)}
.section-rule{border:none;border-top:1px solid var(--border)}
.slabel{font-family:var(--mono);font-size:.7rem;font-weight:500;color:var(--amber);letter-spacing:.18em;text-transform:uppercase;margin-bottom:.9rem}
.stitle{font-size:clamp(1.75rem,3.5vw,2.75rem);font-weight:800;letter-spacing:-.03em;color:#edf0f4;line-height:1.1;margin-bottom:.9rem}
.ssub{font-size:1rem;color:var(--text-dim);max-width:540px;line-height:1.72;margin-bottom:2.8rem}

/* Features */
.feat-grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(300px,1fr));gap:1px;background:var(--border);border:1px solid var(--border);border-radius:6px;overflow:hidden}
.feat{background:var(--bg);padding:1.9rem 1.75rem;transition:background .2s}
.feat:hover{background:var(--bg2)}
.feat-icon{font-size:1.5rem;margin-bottom:.9rem;display:block}
.feat-name{font-size:.97rem;font-weight:700;color:#edf0f4;margin-bottom:.45rem}
.feat-desc{font-size:.87rem;color:var(--text-dim);line-height:1.65}
.feat-tag{display:inline-block;margin-top:.85rem;font-family:var(--mono);font-size:.65rem;font-weight:700;color:var(--amber);background:var(--amber-glow);padding:.18rem .55rem;border-radius:2px;letter-spacing:.04em}

/* Models */
.models-grid{display:grid;grid-template-columns:repeat(auto-fill,minmax(290px,1fr));gap:1px;background:var(--border);border:1px solid var(--border);border-radius:6px;overflow:hidden}
.model{background:var(--bg);padding:1.1rem 1.3rem;display:flex;flex-direction:column;gap:.28rem;transition:background .2s}
.model:hover{background:var(--bg2)}
.model-hdr{display:flex;align-items:baseline;justify-content:space-between;gap:.4rem}
.model-name{font-family:var(--mono);font-size:.83rem;font-weight:700;color:#edf0f4}
.model-q{font-family:var(--mono);font-size:.7rem;color:var(--text-faint)}
.model-vram{font-family:var(--mono);font-size:.73rem;color:var(--cyan)}
.caps{display:flex;flex-wrap:wrap;gap:.28rem;margin-top:.35rem}
.cap{font-family:var(--mono);font-size:.62rem;font-weight:700;padding:.13rem .42rem;border-radius:2px}
.cap.s{color:#ffd700;background:rgba(255,215,0,.09)}
.cap.t{color:var(--green);background:rgba(82,217,138,.1)}
.cap.k{color:var(--amber);background:rgba(245,166,35,.1)}
.cap.u{color:var(--red);background:rgba(224,92,92,.1)}
.cap.d{color:var(--text-dim)}

/* Tools */
.tools-grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(240px,1fr));gap:1.4rem}
.tool{border:1px solid var(--border2);border-radius:5px;padding:1.75rem 1.55rem;background:var(--bg2);position:relative;overflow:hidden;transition:border-color .2s,box-shadow .2s}
.tool:hover{border-color:var(--amber-dim);box-shadow:0 0 22px rgba(245,166,35,.07)}
.tool::before{content:'';position:absolute;top:0;left:0;right:0;height:2px}
.tool.a::before{background:var(--amber)}.tool.g::before{background:var(--green)}.tool.c::before{background:var(--cyan)}.tool.p::before{background:#a78bfa}
.tool-cmd{font-family:var(--mono);font-size:.8rem;font-weight:700;color:var(--amber);margin-bottom:.75rem}
.tool-title{font-size:.97rem;font-weight:700;color:#edf0f4;margin-bottom:.45rem}
.tool-desc{font-size:.86rem;color:var(--text-dim);line-height:1.62}

/* Steps */
.steps{display:grid;grid-template-columns:repeat(auto-fit,minmax(255px,1fr));gap:2.5rem;counter-reset:steps}
.step{counter-increment:steps;position:relative;padding-left:3.3rem}
.step::before{content:counter(steps);position:absolute;left:0;top:.1rem;width:2.1rem;height:2.1rem;border-radius:4px;background:var(--amber-glow);border:1px solid var(--amber-dim);color:var(--amber);font-family:var(--mono);font-weight:700;font-size:.88rem;display:flex;align-items:center;justify-content:center}
.step-title{font-size:.97rem;font-weight:700;color:#edf0f4;margin-bottom:.38rem}
.step-desc{font-size:.87rem;color:var(--text-dim);line-height:1.62}
.step-code{margin-top:.65rem;font-family:var(--mono);font-size:.76rem;color:var(--green);background:var(--bg2);border:1px solid var(--border2);padding:.45rem .75rem;border-radius:3px;display:inline-block}

/* Cmd table */
.cmd-table{border:1px solid var(--border2);border-radius:5px;overflow:hidden;margin-top:2.8rem}
.cmd-header{background:var(--bg3);padding:.75rem 1.15rem;font-family:var(--mono);font-size:.7rem;color:var(--text-faint);letter-spacing:.08em;text-transform:uppercase}
.cmd-grid{display:grid;grid-template-columns:1fr 1fr;gap:1px;background:var(--border)}
.cmd-row{background:var(--bg2);padding:.85rem 1.15rem;display:flex;gap:1.1rem;align-items:baseline}
code.mono{font-family:var(--mono)}

/* Req box */
.req-box{margin-top:3.2rem;padding:1.55rem 1.75rem;border:1px solid var(--border2);border-radius:5px;background:var(--bg);display:flex;flex-wrap:wrap;gap:2.5rem}
.req-col-title{font-family:var(--mono);font-size:.7rem;color:var(--text-faint);letter-spacing:.1em;text-transform:uppercase;margin-bottom:.65rem}
.req-list{list-style:none;display:flex;flex-direction:column;gap:.38rem}
.req-list li{font-size:.88rem;color:var(--text-dim);display:flex;gap:.65rem;align-items:center}

/* Footer */
footer{border-top:1px solid var(--border);padding:2.3rem 2rem;display:flex;align-items:center;justify-content:space-between;flex-wrap:wrap;gap:1rem;background:var(--bg2)}
.foot-l{font-family:var(--mono);font-size:.76rem;color:var(--text-faint)}
.foot-l strong{color:var(--amber)}
.foot-links{display:flex;gap:1.4rem}
.foot-links a{font-family:var(--mono);font-size:.76rem;color:var(--text-dim)}
.foot-links a:hover{color:var(--amber);text-decoration:none}

/* Reveal */
.reveal{opacity:0;transform:translateY(18px);transition:opacity .52s,transform .52s}
.reveal.in{opacity:1;transform:translateY(0)}

/* Animations */
@keyframes fadeUp{from{opacity:0;transform:translateY(14px)}to{opacity:1;transform:translateY(0)}}
@keyframes blink{0%,100%{opacity:1}50%{opacity:0}}
::-webkit-scrollbar{width:5px;height:5px}
::-webkit-scrollbar-track{background:var(--bg)}
::-webkit-scrollbar-thumb{background:var(--border2);border-radius:3px}
@media(max-width:640px){.nav-links{display:none}.hero-title{font-size:2.2rem}.install-strip{flex-direction:column}.copy-btn{border-left:none;border-top:1px solid var(--border2)}.cmd-grid{grid-template-columns:1fr}}
</style>
</head>
<body>

<nav>
  <div class="nav-inner">
    <div class="nav-logo">llm<span>-auto-setup</span></div>
    <div class="nav-links">
      <a href="#features">Features</a>
      <a href="#models">Models</a>
      <a href="#tools">Tools</a>
      <a href="#quickstart">Quick Start</a>
    </div>
    <a class="nav-gh" href="https://github.com/your-repo/llm-auto-setup" target="_blank">
      <svg viewBox="0 0 16 16" fill="currentColor"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/></svg>
      GitHub
    </a>
  </div>
</nav>

<!-- HERO -->
<section id="hero">
  <div class="container">
    <p class="hero-eyebrow">Open Source &nbsp;¬∑&nbsp; Ubuntu 22.04 / 24.04 &nbsp;¬∑&nbsp; WSL2 supported</p>
    <h1 class="hero-title">Run a local LLM<br>on <span class="hl">any hardware</span>.<br>One command.</h1>
    <p class="hero-sub">Scans your CPU, RAM, and GPU. Selects the best fitting model. Installs Ollama, llama-cpp-python, Open WebUI, and autonomous coding tools. Fully offline ‚Äî no API keys, no cloud.</p>
    <div class="badges">
      <span class="badge nv"><span class="dot"></span>NVIDIA CUDA</span>
      <span class="badge amd"><span class="dot"></span>AMD ROCm</span>
      <span class="badge cpu"><span class="dot"></span>CPU-only (AVX/AVX2)</span>
      <span class="badge ub"><span class="dot"></span>Ubuntu 22.04 / 24.04</span>
    </div>
    <div class="install-strip">
      <code class="install-cmd"><span class="ps">$ </span>bash &lt;(curl -fsSL https://raw.githubusercontent.com/your-repo/llm-auto-setup/main/llm-auto-setup.sh)</code>
      <button class="copy-btn" id="cpyBtn" onclick="doCopy()">COPY</button>
    </div>

    <div class="hero-split">
      <div class="hero-bullets">
        <div class="bullet"><span class="bullet-arrow">‚ñ∏</span><div><div class="bullet-title">Hardware auto-detection</div><div class="bullet-body">Reads VRAM from sysfs and nvidia-smi without requiring drivers to be pre-installed. Calculates exact layer counts for hybrid CPU+GPU inference.</div></div></div>
        <div class="bullet"><span class="bullet-arrow">‚ñ∏</span><div><div class="bullet-title">15 curated public models</div><div class="bullet-body">Qwen3, Mistral, Dolphin ‚Äî 1.7B to 32B. All from bartowski's public repos. No Hugging Face token needed.</div></div></div>
        <div class="bullet"><span class="bullet-arrow">‚ñ∏</span><div><div class="bullet-title">Autonomous coworking</div><div class="bullet-body">Open Interpreter + Aider pre-wired to your local model. Code execution, file editing, git integration ‚Äî all offline.</div></div></div>
        <div class="bullet"><span class="bullet-arrow">‚ñ∏</span><div><div class="bullet-title">One sudo prompt, start to finish</div><div class="bullet-body">A background keepalive refreshes credentials every 50 s. Type your password once for the entire 20-minute install.</div></div></div>
      </div>

      <div class="term-win">
        <div class="term-bar">
          <span class="td r"></span><span class="td y"></span><span class="td g"></span>
          <span class="ttl">llm-auto-setup.sh</span>
        </div>
        <div class="term-body" id="tbody"></div>
      </div>
    </div>
  </div>
</section>

<hr class="section-rule">

<!-- FEATURES -->
<section id="features" class="section">
  <div class="container">
    <p class="slabel reveal">What it does</p>
    <h2 class="stitle reveal">Everything set up,<br>nothing left to configure.</h2>
    <p class="ssub reveal">From a bare Ubuntu install to a fully running local LLM stack ‚Äî GPU drivers, model download, and UI all included.</p>
    <div class="feat-grid reveal">
      <div class="feat">
        <span class="feat-icon">üîç</span>
        <div class="feat-name">Hardware scanning</div>
        <div class="feat-desc">Detects NVIDIA via nvidia-smi and AMD via sysfs <code class="mono" style="font-size:.79em">mem_info_vram_total</code> ‚Äî no ROCm needed for the initial VRAM read. Calculates precise GPU/CPU layer split for hybrid inference.</div>
        <span class="feat-tag">STEP 2</span>
      </div>
      <div class="feat">
        <span class="feat-icon">ü§ñ</span>
        <div class="feat-name">Smart model selection</div>
        <div class="feat-desc">Eight GPU tiers plus three CPU-only tiers. Auto-selects the best fit. Override with a numbered picker showing all 15 models, their VRAM requirements, and capability tags.</div>
        <span class="feat-tag">STEP 3</span>
      </div>
      <div class="feat">
        <span class="feat-icon">‚ö°</span>
        <div class="feat-name">GPU acceleration</div>
        <div class="feat-desc">CUDA toolkit auto-installed for NVIDIA. ROCm via <code class="mono" style="font-size:.79em">amdgpu-install</code> for AMD with HIP wheel fallback and <code class="mono" style="font-size:.79em">GGML_HIPBLAS</code> source build. Flash attention + q8_0 KV-cache enabled by default.</div>
        <span class="feat-tag">STEPS 7‚Äì9</span>
      </div>
      <div class="feat">
        <span class="feat-icon">üñ•Ô∏è</span>
        <div class="feat-name">Two chat interfaces</div>
        <div class="feat-desc">Neural Terminal ‚Äî a zero-dependency HTML UI with Markdown rendering and a multi-session sidebar. Open WebUI ‚Äî the full-featured interface with model switching, history, and system prompt support.</div>
        <span class="feat-tag">STEP 13</span>
      </div>
      <div class="feat">
        <span class="feat-icon">üõ†Ô∏è</span>
        <div class="feat-name">Autonomous coworking</div>
        <div class="feat-desc"><code class="mono" style="font-size:.79em">cowork</code> runs Open Interpreter against your local model ‚Äî the AI executes code, browses the web, and manages files. <code class="mono" style="font-size:.79em">aider</code> gives git-integrated pair programming with automatic patch application.</div>
        <span class="feat-tag">STEP 13b</span>
      </div>
      <div class="feat">
        <span class="feat-icon">üîß</span>
        <div class="feat-name">Quality-of-life tools</div>
        <div class="feat-desc">Optionally installs zsh + Oh-My-Zsh, tmux, bat, eza, fzf, btop, nvtop (NVIDIA + AMD + Intel), neofetch, GUI tools. All aliased and ready the moment you open a new terminal.</div>
        <span class="feat-tag">STEP 13a</span>
      </div>
    </div>
  </div>
</section>

<hr class="section-rule">

<!-- MODELS -->
<section id="models" class="section section-alt">
  <div class="container">
    <p class="slabel reveal">Model library</p>
    <h2 class="stitle reveal">15 curated models.<br>All public, no token needed.</h2>
    <p class="ssub reveal">Every model from <a href="https://huggingface.co/bartowski" target="_blank">bartowski's public GGUF repos</a>. The installer picks the best tier automatically ‚Äî or choose from the full list.</p>

    <div class="models-grid reveal">
      <div class="model"><div class="model-hdr"><span class="model-name">Qwen3-14B</span><span class="model-q">Q4_K_M</span></div><span class="model-vram">~9 GB VRAM</span><div class="caps"><span class="cap s">‚òÖ Best 12 GB</span><span class="cap t">TOOLS</span><span class="cap k">THINK</span></div></div>
      <div class="model"><div class="model-hdr"><span class="model-name">Qwen3-30B-A3B</span><span class="model-q">Q4_K_M ¬∑ MoE</span></div><span class="model-vram">~16 GB VRAM</span><div class="caps"><span class="cap s">‚òÖ Best 16 GB</span><span class="cap t">TOOLS</span><span class="cap k">THINK</span></div></div>
      <div class="model"><div class="model-hdr"><span class="model-name">Qwen3-8B</span><span class="model-q">Q6_K</span></div><span class="model-vram">~6 GB VRAM</span><div class="caps"><span class="cap s">‚òÖ Best 8 GB</span><span class="cap t">TOOLS</span><span class="cap k">THINK</span></div></div>
      <div class="model"><div class="model-hdr"><span class="model-name">Qwen3-8B</span><span class="model-q">Q4_K_M</span></div><span class="model-vram">~5 GB VRAM</span><div class="caps"><span class="cap s">‚òÖ Best 6 GB</span><span class="cap t">TOOLS</span><span class="cap k">THINK</span></div></div>
      <div class="model"><div class="model-hdr"><span class="model-name">Qwen3-4B</span><span class="model-q">Q4_K_M</span></div><span class="model-vram">~3 GB VRAM</span><div class="caps"><span class="cap s">‚òÖ Best 4 GB</span><span class="cap t">TOOLS</span><span class="cap k">THINK</span></div></div>
      <div class="model"><div class="model-hdr"><span class="model-name">Qwen3-1.7B</span><span class="model-q">Q8_0</span></div><span class="model-vram">CPU-only</span><div class="caps"><span class="cap t">TOOLS</span><span class="cap k">THINK</span></div></div>
      <div class="model"><div class="model-hdr"><span class="model-name">Qwen2.5-32B</span><span class="model-q">Q4_K_M</span></div><span class="model-vram">~19 GB VRAM</span><div class="caps"><span class="cap s">‚òÖ Best 24 GB</span><span class="cap t">TOOLS</span></div></div>
      <div class="model"><div class="model-hdr"><span class="model-name">Qwen2.5-14B</span><span class="model-q">Q4_K_M</span></div><span class="model-vram">~9 GB VRAM</span><div class="caps"><span class="cap t">TOOLS</span></div></div>
      <div class="model"><div class="model-hdr"><span class="model-name">Qwen2.5-3B</span><span class="model-q">Q6_K</span></div><span class="model-vram">~2 GB VRAM</span><div class="caps"><span class="cap t">TOOLS</span></div></div>
      <div class="model"><div class="model-hdr"><span class="model-name">Mistral-Nemo-12B</span><span class="model-q">Q5_K_M</span></div><span class="model-vram">~8 GB VRAM</span><div class="caps"><span class="cap s">‚òÖ Best 10 GB</span><span class="cap t">TOOLS</span></div></div>
      <div class="model"><div class="model-hdr"><span class="model-name">Mistral-Nemo-12B</span><span class="model-q">Q4_K_M</span></div><span class="model-vram">~7 GB VRAM</span><div class="caps"><span class="cap t">TOOLS</span></div></div>
      <div class="model"><div class="model-hdr"><span class="model-name">Mistral-Small-22B</span><span class="model-q">Q4_K_M</span></div><span class="model-vram">~13 GB VRAM</span><div class="caps"><span class="cap t">TOOLS</span></div></div>
      <div class="model"><div class="model-hdr"><span class="model-name">Dolphin3-8B</span><span class="model-q">Q6_K</span></div><span class="model-vram">~6 GB VRAM</span><div class="caps"><span class="cap u">UNCENSORED</span></div></div>
      <div class="model"><div class="model-hdr"><span class="model-name">Dolphin3-8B</span><span class="model-q">Q4_K_M</span></div><span class="model-vram">~5 GB VRAM</span><div class="caps"><span class="cap u">UNCENSORED</span></div></div>
      <div class="model"><div class="model-hdr"><span class="model-name">Phi-3.5-mini</span><span class="model-q">Q4_K_M</span></div><span class="model-vram">CPU / 2 GB</span><div class="caps"><span class="cap d">3.8B ¬∑ minimal RAM</span></div></div>
    </div>
    <p style="margin-top:1.4rem;font-family:var(--mono);font-size:.74rem;color:var(--text-faint)">
      <span style="color:var(--amber)">‚òÖ</span> = auto-selected for that VRAM tier &nbsp;¬∑&nbsp;
      <span style="color:var(--green)">TOOLS</span> = function/tool calling &nbsp;¬∑&nbsp;
      <span style="color:var(--amber)">THINK</span> = /think / /no_think reasoning mode &nbsp;¬∑&nbsp;
      MoE = 30B quality at 8B speed
    </p>
  </div>
</section>

<hr class="section-rule">

<!-- TOOLS -->
<section id="tools" class="section">
  <div class="container">
    <p class="slabel reveal">What gets installed</p>
    <h2 class="stitle reveal">A complete local AI workstation.</h2>
    <p class="ssub reveal">Every tool pre-configured and aliased ‚Äî type the command, start working.</p>
    <div class="tools-grid reveal">
      <div class="tool a">
        <div class="tool-cmd">chat</div>
        <div class="tool-title">Neural Terminal</div>
        <div class="tool-desc">Zero-dependency HTML chat UI. Markdown rendering, syntax highlighting, multi-session sidebar. Served locally at <code class="mono" style="font-size:.79em">localhost:8090</code>.</div>
      </div>
      <div class="tool g">
        <div class="tool-cmd">webui</div>
        <div class="tool-title">Open WebUI</div>
        <div class="tool-desc">Full-featured web interface with model switching, conversation history, and system prompts. Served at <code class="mono" style="font-size:.79em">localhost:8080</code>. OpenAI integration disabled ‚Äî fully local.</div>
      </div>
      <div class="tool c">
        <div class="tool-cmd">cowork</div>
        <div class="tool-title">Open Interpreter</div>
        <div class="tool-desc">The LLM drives your machine. Executes Python/shell/JS, reads and writes files, browses the web ‚Äî all routed through your local Ollama model, no cloud required.</div>
      </div>
      <div class="tool p">
        <div class="tool-cmd">ai / aider</div>
        <div class="tool-title">Aider</div>
        <div class="tool-desc">AI pair programmer with git integration. Reads your codebase, writes patches, applies them directly. <code class="mono" style="font-size:.79em">--no-auto-commits</code> by default so you review before git sees anything.</div>
      </div>
    </div>

    <div class="cmd-table reveal">
      <div class="cmd-header">All aliases</div>
      <div class="cmd-grid">
        <div class="cmd-row"><code class="mono" style="font-size:.8rem;color:var(--amber);min-width:105px">chat</code><span style="font-size:.84rem;color:var(--text-dim)">Neural Terminal UI ‚Üí :8090</span></div>
        <div class="cmd-row"><code class="mono" style="font-size:.8rem;color:var(--amber);min-width:105px">webui</code><span style="font-size:.84rem;color:var(--text-dim)">Open WebUI ‚Üí :8080</span></div>
        <div class="cmd-row"><code class="mono" style="font-size:.8rem;color:var(--amber);min-width:105px">run-model</code><span style="font-size:.84rem;color:var(--text-dim)">Run default model from CLI</span></div>
        <div class="cmd-row"><code class="mono" style="font-size:.8rem;color:var(--amber);min-width:105px">ask</code><span style="font-size:.84rem;color:var(--text-dim)">Alias for run-model</span></div>
        <div class="cmd-row"><code class="mono" style="font-size:.8rem;color:var(--amber);min-width:105px">cowork</code><span style="font-size:.84rem;color:var(--text-dim)">Open Interpreter (autonomous AI)</span></div>
        <div class="cmd-row"><code class="mono" style="font-size:.8rem;color:var(--amber);min-width:105px">ai / aider</code><span style="font-size:.84rem;color:var(--text-dim)">AI pair programmer w/ git</span></div>
        <div class="cmd-row"><code class="mono" style="font-size:.8rem;color:var(--amber);min-width:105px">ollama-start</code><span style="font-size:.84rem;color:var(--text-dim)">Start Ollama backend</span></div>
        <div class="cmd-row"><code class="mono" style="font-size:.8rem;color:var(--amber);min-width:105px">ollama-pull</code><span style="font-size:.84rem;color:var(--text-dim)">Download any Ollama model</span></div>
        <div class="cmd-row"><code class="mono" style="font-size:.8rem;color:var(--amber);min-width:105px">ollama-list</code><span style="font-size:.84rem;color:var(--text-dim)">List downloaded Ollama models</span></div>
        <div class="cmd-row"><code class="mono" style="font-size:.8rem;color:var(--amber);min-width:105px">ollama-run</code><span style="font-size:.84rem;color:var(--text-dim)">Run any Ollama model tag</span></div>
        <div class="cmd-row"><code class="mono" style="font-size:.8rem;color:var(--amber);min-width:105px">llm-status</code><span style="font-size:.84rem;color:var(--text-dim)">Models, disk, hardware config</span></div>
        <div class="cmd-row"><code class="mono" style="font-size:.8rem;color:var(--amber);min-width:105px">gguf-run</code><span style="font-size:.84rem;color:var(--text-dim)">Run raw GGUF via llama-cpp</span></div>
        <div class="cmd-row"><code class="mono" style="font-size:.8rem;color:var(--amber);min-width:105px">gguf-list</code><span style="font-size:.84rem;color:var(--text-dim)">List downloaded GGUF files</span></div>
        <div class="cmd-row"><code class="mono" style="font-size:.8rem;color:var(--amber);min-width:105px">llm-help</code><span style="font-size:.84rem;color:var(--text-dim)">Full command reference</span></div>
      </div>
    </div>
  </div>
</section>

<hr class="section-rule">

<!-- QUICK START -->
<section id="quickstart" class="section section-alt">
  <div class="container">
    <p class="slabel reveal">Quick Start</p>
    <h2 class="stitle reveal">Up and running<br>in three steps.</h2>
    <p class="ssub reveal">The script handles everything else ‚Äî driver detection, model download, venv setup, alias wiring.</p>
    <div class="steps reveal">
      <div class="step">
        <div class="step-title">Download and run</div>
        <div class="step-desc">Pipe directly to bash. The script scans your hardware first and shows a recommendation box before touching anything.</div>
        <code class="step-code">bash &lt;(curl -fsSL ‚Ä¶/llm-auto-setup.sh)</code>
      </div>
      <div class="step">
        <div class="step-title">Answer the prompts</div>
        <div class="step-desc">Type your sudo password <strong>once</strong>. Confirm the auto-selected model or pick from the full list. Choose optional tools. Watch the install run.</div>
      </div>
      <div class="step">
        <div class="step-title">Open a new terminal</div>
        <div class="step-desc">Aliases load automatically. Run <code class="mono" style="font-size:.85em">chat</code> for the browser UI or <code class="mono" style="font-size:.85em">run-model "hello"</code> to test from the CLI.</div>
        <code class="step-code">chat &nbsp; # ‚Üí http://localhost:8090</code>
      </div>
    </div>

    <div class="req-box reveal">
      <div>
        <div class="req-col-title">Requirements</div>
        <ul class="req-list">
          <li><span style="color:var(--green);font-family:var(--mono)">‚úì</span> Ubuntu 22.04 or 24.04 (WSL2 supported)</li>
          <li><span style="color:var(--green);font-family:var(--mono)">‚úì</span> curl + sudo</li>
          <li><span style="color:var(--green);font-family:var(--mono)">‚úì</span> 8 GB RAM minimum (16 GB recommended)</li>
          <li><span style="color:var(--green);font-family:var(--mono)">‚úì</span> 20 GB free disk space</li>
        </ul>
      </div>
      <div>
        <div class="req-col-title">GPU support</div>
        <ul class="req-list">
          <li><span style="color:#76b900;font-family:var(--mono)">‚úì</span> NVIDIA GTX 10xx ‚Üí RTX 40xx (CUDA 12)</li>
          <li><span style="color:#ed1c24;font-family:var(--mono)">‚úì</span> AMD RX 6000 / 7000 series (ROCm 6.3)</li>
          <li><span style="color:var(--cyan);font-family:var(--mono)">‚úì</span> CPU-only ‚Äî AVX / AVX2 / AVX-512</li>
        </ul>
      </div>
    </div>
  </div>
</section>

<footer>
  <div class="foot-l"><strong>llm-auto-setup</strong> &nbsp;¬∑&nbsp; MIT License &nbsp;¬∑&nbsp; Ubuntu 22.04 / 24.04</div>
  <div class="foot-links">
    <a href="https://github.com/your-repo/llm-auto-setup" target="_blank">GitHub</a>
    <a href="https://github.com/your-repo/llm-auto-setup/issues" target="_blank">Issues</a>
    <a href="https://github.com/your-repo/llm-auto-setup/blob/main/llm-auto-setup.sh" target="_blank">View script</a>
    <a href="https://ollama.com" target="_blank">Ollama</a>
  </div>
</footer>

<script>
function doCopy(){
  const cmd='bash <(curl -fsSL https://raw.githubusercontent.com/your-repo/llm-auto-setup/main/llm-auto-setup.sh)';
  navigator.clipboard.writeText(cmd).then(()=>{
    const b=document.getElementById('cpyBtn');
    b.textContent='COPIED!';b.classList.add('ok');
    setTimeout(()=>{b.textContent='COPY';b.classList.remove('ok');},2000);
  });
}

// Scroll reveal with stagger
const obs=new IntersectionObserver(entries=>{
  entries.forEach(e=>{
    if(!e.isIntersecting)return;
    const kids=e.target.querySelectorAll('.feat,.model,.tool,.step,.cmd-row');
    if(kids.length){
      kids.forEach((c,i)=>{
        c.style.cssText=`opacity:0;transform:translateY(12px);transition:opacity .38s ${i*.045}s,transform .38s ${i*.045}s`;
        requestAnimationFrame(()=>requestAnimationFrame(()=>{c.style.opacity='1';c.style.transform='translateY(0)'}));
      });
    }
    e.target.classList.add('in');
    obs.unobserve(e.target);
  });
},{threshold:.07});
document.querySelectorAll('.reveal').forEach(el=>obs.observe(el));

// Terminal typer
const LINES=[
  {t:'‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ',c:'td2',i:true},
  {t:'  ‚ñ∂  Hardware detection',c:'tc',i:true},
  {t:'‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ',c:'td2',i:true},
  {t:''},
  {t:'  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê',c:'tc'},
  {t:'  ‚îÇ         HARDWARE SCAN RESULTS              ‚îÇ',c:'tc'},
  {t:'  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§',c:'tc'},
  {t:'  ‚îÇ  GPU         AMD Radeon RX 7900 XTX        ‚îÇ',c:'tw'},
  {t:'  ‚îÇ  VRAM        24 GB  (24564 MiB)            ‚îÇ',c:'tw'},
  {t:'  ‚îÇ  API         ROCm (not yet installed)      ‚îÇ',c:'ta'},
  {t:'  ‚îÇ  RAM         32 GB total / 28 GB free      ‚îÇ',c:'tw'},
  {t:'  ‚îÇ  Disk free   480 GB                        ‚îÇ',c:'tw'},
  {t:'  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò',c:'tc'},
  {t:''},
  {t:'  ‚óÜ  24 GB VRAM ‚Üí Qwen2.5-32B [TOOLS] ‚òÖ',c:'ta'},
  {t:''},
  {t:'  ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó',c:'tg'},
  {t:'  ‚ïë       RECOMMENDED CONFIGURATION             ‚ïë',c:'tg'},
  {t:'  ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£',c:'tg'},
  {t:'  ‚ïë  Model       Qwen2.5-32B Q4_K_M            ‚ïë',c:'tw'},
  {t:'  ‚ïë  GPU layers  64 / 64  (~18 GB VRAM)        ‚ïë',c:'tw'},
  {t:'  ‚ïë  Threads     12   Batch: 1024              ‚ïë',c:'tw'},
  {t:'  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù',c:'tg'},
];

const body=document.getElementById('tbody');
let li=0;
function nextLine(){
  if(li>=LINES.length)return;
  const l=LINES[li++];
  const s=document.createElement('span');
  s.style.display='block';
  if(!l.t){s.innerHTML='&nbsp;';body.appendChild(s);setTimeout(nextLine,55);return;}
  if(l.c)s.className=l.c;
  if(l.i){s.textContent=l.t;body.appendChild(s);setTimeout(nextLine,18);return;}
  body.appendChild(s);
  let ci=0;
  const cur=document.createElement('span');
  cur.className='tcur';
  s.appendChild(cur);
  (function type(){
    if(ci<l.t.length){cur.before(document.createTextNode(l.t[ci++]));setTimeout(type,11+Math.random()*7);}
    else{cur.remove();setTimeout(nextLine,38);}
  })();
}
setTimeout(nextLine,800);
</script>
</body>
</html>
